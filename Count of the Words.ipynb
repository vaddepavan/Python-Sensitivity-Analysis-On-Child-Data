{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'length': 61, 'unique': 128, '[/]': 30, '[//]': 8, '[*]': 1, '(.)': 11}, '\\n', {'length': 68, 'unique': 139, '[/]': 34, '[//]': 10, '[*]': 0, '(.)': 18}, '\\n', {'length': 56, 'unique': 126, '[/]': 14, '[//]': 11, '[*]': 1, '(.)': 18}, '\\n', {'length': 67, 'unique': 116, '[/]': 5, '[//]': 10, '[*]': 1, '(.)': 30}, '\\n', {'length': 105, 'unique': 152, '[/]': 27, '[//]': 5, '[*]': 0, '(.)': 13}, '\\n', {'length': 62, 'unique': 138, '[/]': 17, '[//]': 32, '[*]': 1, '(.)': 32}, '\\n', {'length': 73, 'unique': 162, '[/]': 8, '[//]': 14, '[*]': 0, '(.)': 29}, '\\n', {'length': 44, 'unique': 108, '[/]': 11, '[//]': 6, '[*]': 0, '(.)': 10}, '\\n', {'length': 59, 'unique': 150, '[/]': 22, '[//]': 8, '[*]': 0, '(.)': 7}, '\\n', {'length': 66, 'unique': 150, '[/]': 7, '[//]': 10, '[*]': 0, '(.)': 30}, '\\n']\n",
      "[{'length': 73, 'unique': 118, '[/]': 13, '[//]': 9, '[*]': 0, '(.)': 19}, '\\n', {'length': 79, 'unique': 196, '[/]': 20, '[//]': 10, '[*]': 0, '(.)': 32}, '\\n', {'length': 90, 'unique': 209, '[/]': 6, '[//]': 17, '[*]': 0, '(.)': 22}, '\\n', {'length': 73, 'unique': 183, '[/]': 8, '[//]': 9, '[*]': 0, '(.)': 38}, '\\n', {'length': 74, 'unique': 200, '[/]': 17, '[//]': 19, '[*]': 1, '(.)': 33}, '\\n', {'length': 77, 'unique': 176, '[/]': 34, '[//]': 7, '[*]': 0, '(.)': 17}, '\\n', {'length': 85, 'unique': 166, '[/]': 9, '[//]': 19, '[*]': 0, '(.)': 35}, '\\n', {'length': 78, 'unique': 183, '[/]': 16, '[//]': 21, '[*]': 0, '(.)': 32}, '\\n', {'length': 75, 'unique': 180, '[/]': 19, '[//]': 20, '[*]': 0, '(.)': 43}, '\\n', {'length': 87, 'unique': 171, '[/]': 10, '[//]': 10, '[*]': 0, '(.)': 21}, '\\n']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Title         :\tBuilding a child language analyser\n",
    "Author        :\tVADDE PAVAN KUMAR\n",
    "Student Id    :\t29772990\n",
    "Email Id      : pvad0001@student.monash.edu\n",
    "Status        :\tFinal\n",
    "Type          :\tTASK - 2\n",
    "Created       :\t03-10-2018\n",
    "last modified :\t12-10-2018\n",
    "Python-Version:\t3.0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import glob # importing the glob and regular expression re \n",
    "import re\n",
    "class Analyser: # creating the analyser class \n",
    "    def __init__(self): # default constructor created\n",
    "        self.sli_list = [] # Instance variables have been created \n",
    "        self.td_list = []\n",
    "    def __str__(self): # String method magic method returns formated string\n",
    "        return str(self.sli_list) +  \"\\n\" + str(self.td_list)   # converting the list to string and displays when we call the object of the class\n",
    "    def analyse_script(self,cleanedfile): # meth0 created for calucalting the statistics of each file\n",
    "        length = 0 #intializing the length to 0\n",
    "        sli_dict = {} # creating the couple of dictionaries to store the values in key, value format\n",
    "        td_dict = {} \n",
    "        with open(cleanedfile, \"r\") as f: # opening the cleaned file that has been passed as the argument \n",
    "            list_of_lines = [] # creating the list for storing the lines in counting \n",
    "            lines = f.readlines() # reads all the line in the list format \n",
    "            for line in lines:\n",
    "                line = line.replace(\"\\n\",\"\") #removing the new line chararcter for processing\n",
    "                list_of_lines.append(line) # appending all the lines to the new list \n",
    "            for i in range(0, len(list_of_lines)-1): # then checking the length of the file \n",
    "                line = list_of_lines[i] # taking each line \n",
    "                if (line.endswith('.') or line.endswith('?') or line.endswith('!') ): # if each line ends with either .,?,! \n",
    "                    length = length + 1 # then will be counting the line\n",
    "                    line = list_of_lines[i + 1] # increment the line count \n",
    "                else:\n",
    "                    line = list_of_lines[i + 1] # if it dosent end with any of the chararcter then it will just increment the line\n",
    "            if (re.match(r\"^S\",cleanedfile)): # this for if cleaned is starts with i.e, SLI\n",
    "                sli_dict[\"length\"] = length # will storing the length as a key value pair into the dictioanry \n",
    "            else:\n",
    "                td_dict[\"length\"] = length # other wise into the td dictionary\n",
    "            \n",
    "        with open(cleanedfile, \"r\") as file:\n",
    "            line = file.read().split() # reading the line by spliting them with the space\n",
    "            unique_list = [] # craeting the new list for storing the words\n",
    "            for l in line:\n",
    "                l = l.strip(\"[//]\").strip(\"[/]\").strip(\"(.)\").strip(\"(..)\").strip(\"(...)\").strip(\".\").strip(\"?\").strip(\"!\").strip(\",\").strip(\"''\") #removing all the special charactes from the words\n",
    "                unique_list.append(l) # will append each words to the list created\n",
    "            list_set = set(unique_list) # then the list has been converted to the set, so that duplicates are removed\n",
    "            length = len(list_set) # clauclate the length of the list \n",
    "            if (re.match(r\"^S\",cleanedfile)): \n",
    "                sli_dict[\"unique\"] = length # storing the length into the dictionary \n",
    "            else:\n",
    "                td_dict[\"unique\"] = length\n",
    "                \n",
    "        with open(cleanedfile, \"r\") as file: \n",
    "            count = 0\n",
    "            lines = file.readlines() \n",
    "            for line in lines:\n",
    "                if \"[/]\" in line: # if found [/] symbol in the line then will counting them \n",
    "                    count = count + 1 #incrementingthe counter value each time \n",
    "            if (re.match(r\"^S\",cleanedfile)): \n",
    "                sli_dict[\"[/]\"] = count # storing the count into the dictionary \n",
    "            else:\n",
    "                td_dict[\"[/]\"] = count\n",
    "                \n",
    "        with open(cleanedfile, \"r\") as file: \n",
    "            count = 0 # intialize the counter \n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"[//]\" in line: # if found [//] symbol in the line then will counting them\n",
    "                    count = count + 1 #incrementingthe counter value each time \n",
    "            if (re.match(r\"^S\",cleanedfile)):\n",
    "                sli_dict[\"[//]\"] = count # storing the count into the dictionary \n",
    "            else:\n",
    "                td_dict[\"[//]\"] = count\n",
    "                \n",
    "        with open(cleanedfile, \"r\") as file: \n",
    "            count = 0\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"[*]\" in line: # if found [*] symbol in the line then will counting them\n",
    "                    count = count + 1 #incrementingthe counter value each time \n",
    "            if (re.match(r\"^S\",cleanedfile)):\n",
    "                sli_dict[\"[*]\"] = count # storing the count into the dictionary\n",
    "            else:\n",
    "                td_dict[\"[*]\"] = count\n",
    "        \n",
    "        with open(cleanedfile, \"r\") as file: \n",
    "            count = 0\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"(.)\" in line: # if found (.) symbol in the line then will counting them\n",
    "                    count = count + 1 #incrementingthe counter value each time \n",
    "            if (re.match(r\"^S\",cleanedfile)):\n",
    "                sli_dict[\"(.)\"] = count # storing the count into the dictionary\n",
    "            else:\n",
    "                td_dict[\"(.)\"] = count\n",
    "                \n",
    "        if(len(sli_dict) > 1):\n",
    "            self.sli_list.append(sli_dict) # then the dictinary is append to the list \n",
    "            self.sli_list.append(\"\\n\")\n",
    "        if(len(td_dict) > 1):\n",
    "            self.td_list.append(td_dict)\n",
    "            self.td_list.append(\"\\n\")\n",
    "\n",
    "analyser = Analyser() # craeting the object for the Analyser class\n",
    "path_sli = 'SLI_cleaned/*.txt' # providing the path from where to extract the cleaned files to pass as argument to method \n",
    "files = glob.glob(path_sli) # \n",
    "for filename in files:\n",
    "    analyser.analyse_script(filename) # method is called every time for each file\n",
    "path_TD = 'TD_cleaned/*.txt'\n",
    "files = glob.glob(path_TD) \n",
    "for filename in files:\n",
    "    analyser.analyse_script(filename) # method is called \n",
    "print(analyser)\n",
    "\n",
    "\n",
    "f = open(\"SLI-stats.txt\",'w')  # the stats have been saved into the SLI-stas text file, these will be used for analysing \n",
    "for item in analyser.sli_list:\n",
    "    f.write(\"%s\" % item) # writing the list of dictioanries into the file\n",
    "f.close() # closing the file\n",
    "f = open(\"TD-stats.txt\",'w') \n",
    "for item in analyser.td_list:\n",
    "    f.write(\"%s\" % item)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
